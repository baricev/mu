MLE-bench is a benchmark for evaluating AI agents on machine learning engineering tasks using Kaggle competitions. The README describes the leaderboard with agent scores, guidelines for benchmarking (including recommended resources and runtime settings), and how to perform a lighter evaluation using the Low complexity split. It includes instructions for using Git LFS to fetch the dataset.
